# Масштабирование реляционных баз данных

![Масштабирование реляционных баз данных](https://github.com/user-attachments/assets/d0f03a9f-c79d-4121-aeb4-b221a74df53d)

## Введение

Информационные системы в современном мире сталкиваются с **необходимостью обработки растущих объемов данных**, что предъявляет высокие требования к производительности и отказоустойчивости баз данных. Реляционные СУБД остаются популярными благодаря своей надежности, строгой схеме данных и поддержке транзакций ACID. Однако при увеличении нагрузки традиционные подходы к проектированию реляционных баз данных могут стать узким местом, приводя к замедлению работы приложений и ухудшению пользовательского опыта.

В данной статье рассматриваются самые важные стратегии масштабирования реляционных баз данных, включая шардирование и репликацию. Также обсуждаются ключевые проблемы, такие как обеспечение согласованности данных, управление распределенными транзакциями и минимизация задержек в географически распределенных системах.

## Как можно масштабировать реляционные базы данных?

Реляционные базы данных — основа многих приложений, но с ростом нагрузки их производительность может снижаться. Чтобы решить эту проблему, применяют два основных подхода: **вертикальное** и **горизонтальное** масштабирование.

### Вертикальное масштабирование

Вертикальное масштабирование остается самым простым и предсказуемым способом увеличения производительности реляционных СУБД. Этот подход подразумевает улучшение характеристик сервера: добавление процессорных ядер, увеличение оперативной памяти, использование более быстрых дисковых подсистем. Он не требует изменений в архитектуре приложения и сохраняет все преимущества реляционной модели. Главное достоинство вертикального масштабирования — его концептуальная простота. Администратору не нужно перестраивать логику работы приложения или беспокоиться о согласованности распределенных данных. Все транзакции продолжают выполняться на одном узле, гарантируя соблюдение принципов ACID. Технически масштабирование может заключаться как в апгрейде существующего сервера (добавлении ресурсов без замены оборудования), так и в переходе на более мощную конфигурацию. Например, увеличение ресурсов с 4-ядерного CPU на 16-ядерный в рамках того же физического сервера или облачного инстанса может дать значительный прирост производительности.

Однако у этого метода есть принципиальные ограничения. Физические пределы серверного оборудования создают естественный "потолок" для масштабирования. Современные серверы верхнего уровня могут иметь до нескольких терабайт RAM и сотни процессорных ядер, но их стоимость становится непропорционально высокой. Экономика облачных решений усугубляет эту проблему: цены на мощные инстансы растут нелинейно — переход с 8-ядерной конфигурации PostgreSQL на 64-ядерную может увеличить стоимость в 10–15 раз при реальном приросте производительности всего в 4–6 раз. Кроме того, остается проблема единой точки отказа — выход сервера из строя парализует всю систему.

### Горизонтальное масштабирование

В отличие от вертикального, горизонтальное масштабирование позволяет расширять систему без жёстких ограничений за счёт добавления новых серверов или узлов в распределённую инфраструктуру. Такой подход не только повышает производительность, распределяя нагрузку между несколькими экземплярами базы данных, но и улучшает отказоустойчивость системы.

Горизонтальное масштабирование может быть реализовано с помощью шардинга (разделения данных между серверами) и репликации (создания копий данных для повышения доступности). Этот метод особенно востребован в высоконагруженных системах, где важно обеспечить масштабируемость и надёжность.

## Репликация

**Репликация** — это процесс создания копий базы данных на разных серверах, которые могут использоваться для обработки запросов на чтение. Репликацию можно классифицировать по следующим характеристикам:
- **По архитектуре репликации** между собой выделяют: репликация с одним ведомым узлом (Master-slave replication), репликация с несколькими ведомыми узлами (Multi-master replication), репликация без ведомых узлов (Masterless replication).
- **По принципу синхронизации** на остальные узлы выделяют: асинхронную, синхронную и каскадную репликацию.
- **По уровню передачи данных** на остальные узлы выделяют: физическую и логическую репликацию.

**..тут можно ещё что-то добавить, чтобы текст читался более лаконично...**

### Master-Slave репликация

Такой подход к репликации считается наиболее распространённым. Его суть заключается в чётком распределении ролей между узлами: ведущий сервер (master) обрабатывает все операции записи и часть запросов на чтение, тогда как ведомые серверы (slave) синхронизируют данные с мастером и обслуживают исключительно запросы на чтение.

[Схема 1: схема работы Master-slave репликации]

Когда поступает запрос на изменение данных — будь то добавление (INSERT), обновление (UPDATE) или удаление (DELETE) - первым его обрабатывает мастер-узел. Он выступает в роли центрального координатора, фиксируя все изменения. Однако настоящая "магия" происходит дальше, когда эти изменения необходимо распространить на подчинённые узлы.

На этом этапе система предлагает два принципиально разных механизма синхронизации. Первый - физическая репликация, при которой данные передаются в "сыром" бинарном виде, без преобразований.

[Схема 1: формат данных, который передаётся из узела в узел]

Физическая репликация работает на низком уровне, передавая между узлами не SQL-операции, а сами бинарные изменения данных. Когда мастер-узел выполняет изменение, он сначала записывает его в специальный журнал — WAL в PostgreSQL или binlog в MySQL. Эти журналы содержат не логические команды, а физические изменения страниц данных: какие именно байты и где были изменены.

С технической точки зрения, такой подход означает, что реплики получают и применяют изменения в том же виде, в каком они были записаны на мастере — бит в бит. Это обеспечивает максимальную точность репликации, но накладывает серьёзные ограничения:

- Использовать одинаковую версию СУБД (хотя в PostgreSQL допускается работа между разными патч-версиями при условии совпадения мажорных версий)
- Работать на совместимом железе (с учётом особенностей архитектуры, например, порядка байт)

Главное преимущество физической репликации - её эффективность. Поскольку изменения передаются и применяются в "сыром" виде, системе не нужно тратить ресурсы на парсинг SQL-запросов или преобразование форматов. Однако за такую эффективность приходится платить гибкостью — например, нельзя реплицировать только отдельные таблицы или преобразовывать данные в процессе репликации.

Теперь рассмотрим второй подход - логическую репликацию. Это более совершенный и интеллектуальный метод взаимодействия между узлами.

[Схема 2: формат данных, который передаётся из узела в узел]

При логической репликации мастер-узел передаёт не сырые данные, а последовательность операций изменения — своеобразный журнал событий в формате "я выполнил INSERT в таблицу users" или "я сделал UPDATE для товара с ID 42". Это похоже на то, как разработчик коммитит в Git не сами файлы, а изменения между версиями.

Такой подход открывает принципиально другие возможности по сравнению с бинарной репликацией. Во-первых, появляется возможность выборочной синхронизации — можно реплицировать только определённые таблицы или даже отдельные столбцы. Во-вторых, снимаются ограничения на версионность — мастер и реплика могут работать на разных версиях СУБД, так как команды DML остаются совместимыми. В-третьих, данные можно трансформировать на лету — например, фильтровать конфиденциальную информацию или преобразовывать форматы.

Ключевым элементом этой архитектуры становится механизм синхронизации. Он определяет, как обеспечивается консистентность данных при параллельных операциях, какой лаг репликации считается допустимым и как разрешаются конфликты, когда одна и та же запись изменяется одновременно на мастере и реплике.

В этом процессе обмена данными особую роль играет принцип синхронизации, к рассмотрению которого мы сейчас перейдем.

#### Принципу синхронизации данных между узлами

В системах репликации данных применяются два принципиально разных подхода, различающихся по своим гарантиям и характеристикам производительности. Рассмотрим их ключевые особенности.

**Синхронная репликация** обеспечивает максимальную надежность за счет строгого порядка операций. При получении запроса на запись мастер-узел сначала рассылает данные всем репликам и ожидает явного подтверждения от каждой из них. Только после получения подтверждений от всех реплик (или заданного кворума) операция считается успешной и клиент получает ответ. Такой подход гарантирует сохранность данных и их согласованность на всех узлах, но имеет существенные ограничения. Производительность системы определяется самым медленным узлом, а географическая распределенность значительно увеличивает задержки. Главный недостаток - отказ даже одной реплики приводит к невозможности подтверждения операций, что может парализовать всю систему.

[Схема 4: последовательность при синхронной репликации]

**Асинхронная репликация** предлагает противоположный компромисс. Мастер-узел подтверждает запись клиенту сразу после локального выполнения, не дожидаясь обработки репликами. Изменения передаются подчиненным узлам в фоновом режиме по мере возможности. Это обеспечивает высокую производительность и устойчивость к временным сбоям реплик, поскольку система продолжает работать даже при их недоступности. Однако такой подход несет риски потери данных - если мастер выйдет из строя до завершения синхронизации, последние изменения могут быть утрачены. Кроме того, реплики могут временно содержать неактуальные данные.

[Схема 3: последовательность действий при асинхронной репликации]

Основное различие между подходами заключается в ключевом компромиссе распределенных систем - между надежностью и производительностью. Синхронная репликация обеспечивает максимальную сохранность данных, но ценой снижения скорости работы и доступности системы. Асинхронная репликация, напротив, предлагает высокую производительность и отказоустойчивость, однако допускает возможность потери данных и временной несогласованности - эти аспекты мы подробно рассмотрим далее.

| Проблема |	Последствия	| Методы решения |
|----------|--------------|----------------|
| Временная рассогласованность | Пользователи видят устаревшие данные |	- Временные маркеры "обновляется" - Чтение после записи (read-after-write) для критичных данных
| Риск потери данных | Последние изменения пропадают при сбое мастера |	- Полусинхронная репликация для критичных операций - WAL-логи с подтвержденной записью
| Конфликты обновлений | Конкурирующие изменения на разных узлах | - Векторные часы для определения порядка - Алгоритмы разрешения конфликтов (CRDT)
| Накопление отставания |	Реплики не успевают за мастером при нагрузке | - Автомасштабирование реплик - Ограничение скорости записи

##### Потеря данных при сбое ведущей ноды

НЕ СОВСЕМ ПОНЯТНО, ЧТО ИМЕЕТСЯ ВВИДУ В ЭТОЙ ЧАСТИ

Асинхронная репликация предполагает первоначальную запись данных исключительно на мастер-узел с последующей передачей на реплики с некоторой задержкой. Это создаёт временное окно неконсистентности данных. В случае аварийного отказа мастера до завершения репликации, непереданные изменения безвозвратно теряются.

**Полусинхронная репликация (Semi-synchronous replication)** вводит дополнительное условие: транзакция считается выполненной только после получения подтверждения как минимум от одной реплики. Этот компромиссный вариант существенно снижает риски потери данных при сохранении приемлемого уровня производительности.

**Клиентское журналирование** позволяет приложениям сохранять транзакции локально до их подтверждения ведущим узлом. При возникновении сбоев возможна повторная отправка операций. Однако данная методика существенно усложняет общую архитектуру системы.

**Промежуточный кэширующий слой (например, WAL Proxy)** предлагает альтернативное решение: данные первоначально записываются в устойчивый журнал транзакций, который затем параллельно реплицируется как на ведущий узел, так и на реплики.

##### Задержка репликации (replication lag)

Из-за отсутствия синхронизации в реальном времени, данные на репликах могут отставать от мастера на значительное время, особенно под высокой нагрузкой.

**Мониторинг и алерты по lag-метрикам** - использование метрик вроде Seconds_Behind_Master (MySQL) позволяет отслеживать задержку. В случае повышения порогов можно временно исключить реплику из пула чтения.

**Разделение нагрузки между мастером и репликами** - Минимизация чтений/записей, чтобы уменьшить отставание.

**Использование более эффективных протоколов репликации** - например, физическая репликация быстрее логической, особенно при большом количестве DML-операций.

**Аппаратные улучшения** - быстрые диски (NVMe), оптимизация сетевого стека, увеличесние буферов и размер пакетов в настройках репликации.

##### Несогласованность данных

Из-за задержки данные на репликах не гарантируют точного соответствия мастеру. Это особенно критично для сценариев, где читается недавно записанная информация (Read-Your-Writes Consistency).

**Согласованное маршрутизирование запросов** - использование middleware или proxy, которые маршрутизируют клиентские запросы так, чтобы клиенты после записи всегда читали с мастера.

**Версионирование данных** - система может отслеживать версии объектов и сравнивать их между узлами, обеспечивая согласованность при необходимости.

**Использование CRDT** (???) - для специфических доменов можно применять структуры, допускающие асинхронную репликацию с разрешением конфликтов без потери данных.

##### Failover и Split-Brain

В случае выхода мастера из строя и автоматического переключения на реплику може произойти ситуация split-brain - одновременная запись в два несовместимых источника истины.

**Использование механизмов quorum'a** - репликация и выбор мастера осуществляется на основе большинства (например, через Raft или Paxos), исключая возможность split-brain

**Fencing токены (например, Zookeeper fencing)** - каждому лидеру выдаётся уникальный токен, предотвращающий "двойное лидерство"

**Использование consensus-сервисов** - etcd, consul, zookeeper обеспечивает отказоустойчивый контроль за лидерством и конфигурацией.

**Выбор стратегий автоматического или ручного failover** - в критичных системах предпочтительнее использовать ручной failover с предварительным анализом состояния реплик.

На практике часто используют **гибридные решения**. Например, в PostgreSQL можно настроить синхронную репликацию только для критически важных транзакций, а всё остальное пускать асинхронно.

[Схема 5: пример гибридной настройки]

Или сделать синхронной только одну из нескольких реплик — это даёт баланс между надёжностью и производительностью.

Главный выбор здесь — между скоростью и надёжностью. Для социальной сети, где можно на секунду потерять последний лайк, подойдёт асинхронный вариант. А для банковских операций или медицинских систем, где каждая запись должна быть сохранена наверняка, без синхронной репликации не обойтись

[Схема 6: сравнительная таблица подходов]

##### Multi-Master репликация

Представьте базу данных, где не один, а сразу несколько серверов могут принимать запросы на запись. Это не классическая master-slave схема, к которой многие привыкли, а более современный и гибкий подход — multi-master репликация. Но в чём принципиальная разница между этими подходами и когда стоит выбирать каждый из них? Почему это вообще понадобилось?

Классическая master-slave схема долгое время была стандартом де-факто. Один главный сервер принимает все записи, а его подчинённые лишь читают данные. Просто, надёжно, но... Когда приложение растёт, этот единственный мастер превращается в узкое горлышко. Представьте стадион с сотней входов, но только одной кассой — очереди неизбежны.

Именно здесь multi-master репликация предлагает элегантное решение. Теперь касс несколько, и посетители могут выбирать любую. Для глобальных сервисов это особенно ценно — пользователи в разных частях света пишут в ближайший к ним узел, не испытывая задержек из-за расстояний.

Как это работает в реальности?

Допустим, у нас два мастера — в Москве и во Владивостоке. Пользователь из Приморья вносит изменения, которые сначала попадают на локальный узел. Фокус в том, что система не заставляет его ждать, пока данные доберутся до московского сервера. Вместо этого она говорит: "Хорошо, я приняла твои изменения здесь, а синхронизацией займусь потом".

Это "потом" — ключевой момент. Репликация происходит асинхронно, что даёт потрясающую отзывчивость, но создаёт интересные ситуации. Например, пока изменение путешествует между узлами, два пользователя в разных городах могут видеть разное состояние одних и тех же данных. Но всё не так просто, как кажется.

Главная головоломка multi-master — конфликты. Что если два мастера одновременно изменят одну и ту же запись? Здесь в игру вступают различные стратегии:
- Можно просто взять последнее изменение по времени (Last Write Wins)
- Или попытаться объединить изменения (как это делает Git при мердже веток)
- А иногда приходится звать администратора, чтобы он вручную разобрался, чья правда важнее

Ещё один нюанс — производительность. Казалось бы, больше серверов — больше мощности. Но вся эта синхронизация между узлами съедает немало ресурсов. Порой проще нарастить один мощный сервер, чем городить кластер.

Когда это действительно нужно?
- Если ваше приложение:
- Распределено географически
- Испытывает высокую нагрузку на запись
- Может мириться с временными несоответствиями данных

...то multi-master может стать отличным выбором. Но для банковских систем или там, где важна абсолютная согласованность, лучше поискать другие варианты.

##### Каскадная репликация

Это тип репликации, при котором слейв-сервер может быть реплицирован на другие слейв-сервера. В этой архитектуре изменения, сделанные на **мастер-сервере**, сначала транслируются на первый уровень реплик, а затем от них — к последующим репликам.

Преимущества каскадной репликации:
- **Оптимизация нагрузки**: Избегается перегрузка мастера и первого уровня реплик, так как реплики могут делегировать часть своих запросов другим репликам.
- **Масштабируемость**: Легко расширять систему за счёт добавления новых слейв-реплик на каждом уровне, что позволяет эффективно распределять нагрузку.
- **Уменьшение трафика на мастер-сервере**: Мастер-сервер загружен только первичной репликацией, а остальные реплики могут передавать данные каскадно, снижая нагрузку на основную базу данных.

Недостатки каскадной репликации:
- **Дополнительная задержка**: Из-за того, что данные передаются через несколько уровней реплик, возникает дополнительная задержка в репликации данных, что может привести к рассогласованию на разных уровнях.
- **Сложность в настройке и управлении**: Поддержка каскадной репликации требует более сложной настройки и мониторинга, так как нужно отслеживать состояние всех уровней реплик.

## Шардирование

Шардирование — это техника логического разделения данных на независимые сегменты, называемые шардами, каждый из которых может храниться и обрабатываться отдельным сервером. Благодаря этому можно значительно повысить пропускную способность системы и устранить узкие места в производительности. Важно, что каждый элемент данных принадлежит только одному шару, что упрощает маршрутизацию запросов и минимизирует избыточность.

## Типы шардирования

Существует два основных типа шардирования:

- **Горизонтальный** — разделение данных по строкам: каждая таблица дублируется на всех узлах, но содержит разные записи.
- **Вертикальный** — разделение по столбцам: каждый узел хранит только определённые поля таблиц или подмножества таблиц, соответствующие различным подсистемам.

[Схема 1: Горизонтальное vs. вертикальное шардирование]

Методов определения, к какому шарду должны попасть данные, существует множество, каждый из которых подходит под разные сценарии использования:

- **Хеширование ключа (hash-based)** — применяется хеш-функция к уникальному ключу записи. Полученное значение определяет шард, в который отправятся данные. Этот подход обеспечивает равномерное распределение, но затрудняет выполнение диапазонных запросов.
- **Диапазон значений (range-based)** — данные распределяются по диапазонам значений, например: ID 1–1000 в один шард, 1001–2000 в другой. Удобен для аналитических и выборочных операций, но подвержен риску "горячих точек" при неравномерном росте данных.
- **Географическое шардирование (geo-based)** — данные делятся по региональному признаку, чтобы минимизировать сетевые задержки. Часто используется в глобальных системах для локализации трафика.
- **Функциональное (или доменное) шардирование** — распределение по логике приложения: одни таблицы (например, пользователи) идут в один кластер, другие (например, заказы или логи) — в другой. Часто применяется в микросервисных архитектурах.
- **Динамический или автоматический шардинг** — распределение и перераспределение данных осуществляется автоматически в зависимости от текущей нагрузки, объёма или плотности данных. Такие механизмы используются, например, в MongoDB, CockroachDB или Vitess.

[Схема 2: Примеры методов шардирования]

## Добавление нового шарда

С увеличением объёма данных и ростом нагрузки на систему может возникнуть необходимость в добавлении новых шардов для поддержания масштабируемости. Это достаточно сложный процесс, который требует точной координации и внимательного подхода, чтобы минимизировать влияние на производительность и доступность системы.

### Основные подходы добавления нового шарда

Процесс добавления нового шарда зависит от используемой архитектуры и инструментов, однако существует несколько общих стратегий, которые могут быть применены в разных случаях.

#### Ручное решардирование

Решардирование вручную — это базовый подход, при котором данные переносятся с существующих шардов на новый вручную, а затем обновляется конфигурация маршрутизации запросов. Это довольно трудоёмкий процесс, требующий точности, поскольку ошибки могут привести к несогласованности данных или к нарушению работы системы.

Решардирование вручную обычно включает несколько этапов:
- Создание нового шарда с соответствующей конфигурацией.
- Перераспределение данных, например, с помощью скриптов или специализированных утилит.
- Обновление маршрутизации запросов, чтобы новые данные могли быть направлены на свежий шард.
- Обеспечение целостности данных в процессе переноса.

Этот метод подходит для систем, где перерывы в обслуживании или небольшие простои могут быть допустимы, или для простых систем с относительно небольшим количеством шардов. **Преимущества**:
- Полный контроль над процессом.
- Гибкость в решении уникальных задач.

[Схема 3: Процесс ручного решардирования]

#### Решардирование с использованием Middleware

Множество современных распределённых СУБД применяют middleware решения, такие как Vitess, Citus или Yugabyte, которые автоматизируют процесс ребалансировки данных и обновления маршрутов запросов без необходимости в даунтайме. Эти инструменты абстрагируют сложность решардирования и обеспечивают непрерывную работу системы в процессе расширения.

Vitess (к примеру) управляет шардами и отвечает за автомат* автоматическое перераспределение данных, когда добавляются новые шарды. Это позволяет избежать простоя системы и минимизировать риски, связанные с человеческим фактором. **Преимущества**:
- Автоматизация процесса решардирования.
- Минимизация простоя и рисков ошибок.
- Высокая степень интеграции с современными распределёнными СУБД.

[Схема 4: Решардирование с использованием middleware]

#### Прокси или маршрутизаторы

Прокси-сервера или маршрутизаторы — это подход, при котором добавление новых шардов происходит без изменений на стороне клиента. В этом случае на промежуточном уровне (например, с использованием инструмента типа ProxySQL или Vitess Proxy) работает маршрутизатор, который управляет распределением запросов и определяет, какой шард обслуживает каждый запрос.

Когда добавляется новый шард, маршрутизатор автоматически перенаправляет запросы на правильные узлы, что позволяет масштабировать систему без необходимости изменять клиентскую логику. **Преимущества**:
- Отсутствие изменений в логике приложения.
- Простота интеграции новых шардов.
- Снижение операционных рисков, связанных с изменениями на клиентской стороне.

[Схема 5: Работа прокси-роутера]

#### Online Resharding и Dual Writes
Чтобы минимизировать даунтайм и риски потери данных, при добавлении нового шарда часто используется online resharding. Этот метод включает в себя использование dual writes — временной записи данных как в старые, так и в новые шарды. Во время такого процесса данные пишутся одновременно в оба шарда (старый и новый), а затем проводится фоновый перенос данных на новый шард.

Процесс может включать следующие этапы:
- Включение временной записи в оба шардовых узла (старый и новый).
- Постепенный перенос данных на новый шард в фоновом режиме.
- По завершению переноса данных — остановка записи на старый шард.

Этот метод помогает свести к минимуму время простоя и гарантировать, что все записи данных будут успешными, даже если они происходят во время переноса. **Преимущества**:
- Минимизация времени простоя.
- Обеспечение целостности данных в процессе переноса.

[Схема 6: Процесс online resharding]

## Балансировка нагрузки

Шардирование должно обеспечивать равномерную нагрузку на все узлы. Без должной балансировки даже при наличии множества шардов часть из них может перегружаться, в то время как другие остаются незадействованными.

- При range-шардировании часто возникают горячие шарды, особенно если новые записи всегда попадают в один и тот же диапазон.
- Hash-шардирование даёт более равномерное распределение, но при добавлении новых шардов необходимо перераспределение ключей.

Для минимизации горячих точек можно использовать **согласованное хэширование** (consistent hashing), которое минимизирует перемещение данных при добавлении или удалении узлов. Алгоритм назначает данные ближайшему узлу на кольце хэшей, что упрощает масштабирование.

**Практический вопрос**: Как обнаружить и устранить горячие точки?
- **Ответ**: Мониторьте метрики нагрузки на шарды (например, `queries_per_shard` в Citus или `cpu_usage_per_shard` в Vitess) с помощью Prometheus и Grafana. Если один шард перегружен, перераспределите данные с помощью `rebalance_table_shards` (Citus) или `Reshard` (Vitess). Для предотвращения используйте хэширование по ключу с высокой кардинальностью, например, `user_id` вместо `region`.

[Схема 7: Горячие точки и ребалансировка]

## Affinity и Anti-Affinity

По мере роста объёма данных и распределения нагрузки по нескольким шардовым узлам перед разработчиками встаёт не только задача эффективного масштабирования, но и вопрос логического размещения данных. Одним из ключевых принципов, влияющих на производительность и устойчивость системы, становится выбор между affinity и anti-affinity стратегиями при шардинге.

### Affinity: стремление к связности
Affinity (от англ. "связанность") — это архитектурный принцип, согласно которому логически связанные сущности (например, пользователь и его заказы) хранятся в одном и том же шарде. Такой подход облегчает выполнение транзакций, ускоряет JOIN-запросы и снижает частоту кросс-шардового взаимодействия.

Представим себе систему электронной коммерции: пользователь, его корзина, заказы и платежи — все эти данные постоянно взаимодействуют друг с другом. Если они размещены на одном узле, система может обрабатывать типичные запросы (например, «показать историю заказов пользователя») без необходимости обращаться к другим шардовым нодам. Это особенно критично для OLTP-нагрузок, где важны транзакционность и задержки. **Преимущества affinity-шардинга**:
- Минимизация сетевого взаимодействия. Все данные находятся рядом — запросы не пересекают границы шардов.
- Ускорение транзакций. В большинстве СУБД транзакции внутри одного узла значительно быстрее и проще, чем мультишардовые.
- Простота обеспечения согласованности. Принципы ACID легко соблюдаются, поскольку нет необходимости координировать изменения между несколькими шардами.

[Схема 8: Affinity-шардирование]

**Пример**: В Shopify данные магазина и его заказов хранятся на одном шарде, что ускоряет запросы типа `SELECT * FROM orders WHERE shop_id = ?`.

### Anti-Affinity: диверсификация и устойчивость
В противоположность подходу "всё в одном месте", anti-affinity предполагает преднамеренное разнесение логически связанных сущностей по разным шардам. На первый взгляд это усложняет архитектуру, но на практике часто оказывается необходимым для повышения отказоустойчивости и распределения нагрузки.

Такой подход полезен, например, в системах, где одна группа данных может полностью "захватить" узел. Допустим, крупный клиент в CRM-системе начинает активно генерировать активность (например, тысячами создаёт записи). Если все его данные хранятся на одном узле — это быстро приводит к перегрузке. Разнесение данных клиента по нескольким шардам помогает сбалансировать нагрузку. **Преимущества anti-affinity-шардинга**:
- Изоляция сбоев. Сбой одного шарда не приводит к полной недоступности данных определённого пользователя или сегмента.
- Лучшее распределение нагрузки. Даже активные клиенты не перегружают один узел.
- Масштабируемость по ширине. Легче равномерно расти за счёт увеличения числа нод.

[Схема 9: Anti-Affinity-шардирование]

**Пример**: В Salesforce логи активности клиента распределяются по разным шардам, чтобы избежать перегрузки одного узла.

### Когда применять каждый подход
Выбор между affinity и anti-affinity нельзя считать универсальным — он зависит от требований системы:

| **Сценарий**                              | **Предпочтительный подход** |
|-------------------------------------------|-----------------------------|
| Высокочастотные JOIN-запросы              | Affinity                   |
| Низкий уровень доверия к одному узлу      | Anti-affinity              |
| Работа с транзакциями                     | Affinity                   |
| Доминирование одного клиента в нагрузке   | Anti-affinity              |
| Высокие требования к отказоустойчивости   | Anti-affinity              |
| Минимизация сетевых задержек              | Affinity                   |

**Практический вопрос**: Как выбрать между affinity и anti-affinity для системы электронной коммерции?
- **Ответ**: Используйте affinity для связанных данных (например, пользователь и его заказы), чтобы ускорить транзакции и JOIN-ы. Для логов активности или аналитических данных применяйте anti-affinity, чтобы избежать горячих точек от активных пользователей. Гибридный подход: храните ключевые данные на одном шарде, а второстепенные распределяйте.

Некоторые современные системы (например, Spanner, CockroachDB, YugabyteDB) реализуют динамические стратегии размещения данных, где принципы affinity применяются гибко: в зависимости от текущей активности узел может "перетягивать" к себе связанные данные, чтобы уменьшить межшардовое взаимодействие.

### Гибридный подход
На практике чаще всего используется гибридный подход: наиболее важные логические связи группируются внутри шарда, а второстепенные — распределяются по другим узлам. Например, можно гарантировать, что пользователь и его заказы всегда на одном шарде, но его активность в чатах или история входов может храниться отдельно.

Такой компромисс позволяет соблюсти баланс между производительностью, отказоустойчивостью и масштабируемостью.

## Маршрутизация

Мы распределили данные по нескольким узлам на разных машинах, но остаётся важный вопрос: как клиенту определить, к какому узлу обратиться при выполнении запроса? Когда секции (шарды) перераспределяются — например, при добавлении или удалении узлов — меняется и их размещение. Поэтому нужен централизованный механизм, который будет отслеживать текущее состояние кластера и сможет сообщить клиенту куда обратиться чтобы получить нужные данные. В общем случае это называется Service Discovery, если эта тема интересна, разберем ее в следующей статье. А в частности — существует множество подходов к реализации service discovery в системах с шардированием и динамическим масштабированием. Вот несколько популярных решений и стратегий:

- **Централизованный каталог (реестр) узлов**: Системы вроде Consul, etcd или ZooKeeper хранят актуальную информацию о том, какие шарды где находятся. Клиенты или прокси могут запрашивать у них адрес нужного узла, отвечающего за конкретный диапазон данных.
- **Прокси-роутер перед клиентами**: Клиенты обращаются не напрямую к узлам, а к прокси-серверу, который уже знает всё о текущем состоянии шардинга и маршрутизирует запросы. Такой подход используется, например, в Vitess (MySQL) или Citus (PostgreSQL).
- **Согласованное хэширование (Consistent Hashing)**: Клиент сам вычисляет, к какому узлу ему нужно обратиться, используя кольцо хэшей. Но при этом должен знать текущее состояние узлов (карту кольца), которая всё равно должна где-то поддерживаться — например, через тот же etcd.
- **DNS-based Discovery (через обновляемые DNS-записи)**: адреса сервисов или узлов обновляются через DNS. Преимущество — простота, но минус в том, что обновления не мгновенные и не дают детального контроля.
- **Kubernetes API для сервисов в k8s**: В Kubernetes discovery встроен: клиенты узнают адреса подов и сервисов через Kube DNS или API Kubernetes. Также поддерживаются headless-сервисы для доступа напрямую к подам.

**Практический вопрос**: Как обеспечить надёжную маршрутизацию в Vitess?
- **Ответ**: Настройте Vitess Proxy для автоматического обновления карты шардов через ZooKeeper или etcd. Используйте метрики `vtgate_query_latency` для мониторинга задержек маршрутизации и настройте алерты на ошибки маршрутизации через Prometheus.

[Схема 10: Механизмы маршрутизации]

## Кросс-шардовые запросы

При работе с распределёнными базами данных часто возникает необходимость выполнения запросов, которые требуют данных из нескольких шардов. Это приводит к нескольким техническим проблемам и увеличивает сложность обработки таких запросов. Рассмотрим основные методы решения этих проблем и подходы к оптимизации кросс-шардовых запросов.

### Fan-out
Fan-out — это подход, при котором запрос рассылается на все шардовые узлы, и результаты агрегируются в едином месте. Такой метод полезен, когда необходимо выполнить однотипную операцию на всех шардах, например, когда нужно собрать информацию о пользователях с разных регионов или выполнить поиск по всем данным.

**Проблемы**:
- **Производительность**: чем больше шардов, тем дольше будет время отклика, так как запросы должны быть отправлены на каждый шард и потом собраны.
- **Согласованность**: могут возникнуть проблемы с синхронизацией данных между шардовыми узлами, особенно если на одном из шардов произошли изменения во время выполнения запроса.

Для оптимизации этого подхода часто используется кэширование промежуточных результатов, чтобы избежать повторной обработки одинаковых запросов. **Преимущества**:
- Простота реализации.
- Подходит для аналитических запросов, где важно собрать данные с нескольких источников.

[Схема 11: Fan-out запросы]

**Практический вопрос**: Как ускорить fan-out запросы в Citus?
- **Ответ**: Используйте `citus.explain` для анализа плана запроса. Если запрос затрагивает все шарды, денормализуйте данные или добавьте вторичные индексы. Кэшируйте результаты в Redis для повторяющихся запросов.

### Federated Query Layer
Federated Query Layer — это промежуточный слой, который анализирует запрос, разбивает его на подзапросы и затем собирает итоговый результат. Этот подход позволяет выполнять кросс-шардовые запросы более эффективно, так как промежуточный слой может оптимизировать запросы, направлять их только на те шарды, которые содержат нужные данные, а затем агрегировать результаты.

Примером таких решений являются Citus или Vitess, которые могут анализировать запросы и автоматически распределять их между нужными шардовыми узлами, минимизируя нагрузку. **Преимущества**:
- Эффективное распределение запросов.
- Уменьшение нагрузки на каждый отдельный шард.
- Возможность реализации сложных аналитических запросов через единый интерфейс.

[Схема 12: Federated Query Layer]

### Денормализация
Денормализация — это метод, при котором данные из разных таблиц или шардов могут дублироваться для минимизации необходимости в кросс-шардовых JOIN-ах. Этот подход помогает ускорить запросы, так как вместо того, чтобы делать JOIN между шардовыми узлами, все необходимые данные уже присутствуют в одном месте.

Такой подход используется в распределённых системах, где производительность важнее, чем точная нормализация данных. Например, можно создать отдельные таблицы с денормализованными данными, которые будут содержать всю информацию, необходимую для определённых типов запросов. **Преимущества**:
- Ускоряет выполнение запросов, уменьшив количество кросс-шардовых операций.
- Снижается нагрузка на сеть и увеличивается скорость обработки данных.

**Недостатки**:
- Увеличение объёма данных.
- Требуется дополнительная логика для синхронизации дублированных данных при изменениях.

[Схема 13: Денормализация данных]

**Практический вопрос**: Как синхронизировать денормализованные данные?
- **Ответ**: Используйте триггеры или materialized views в PostgreSQL для автоматического обновления денормализованных таблиц. В Vitess настройте VReplication для синхронизации данных между шардами.

### Кросс-шардовые транзакции
Кросс-шардовые транзакции — это сложные транзакции, которые охватывают несколько шардов. Реализация таких транзакций требует особого подхода для обеспечения целостности и согласованности данных. Наиболее распространённым решением является использование двухфазного коммита (2PC).

2PC (Two-Phase Commit) — это протокол, который обеспечивает атомарность транзакций. Он состоит из двух фаз: в первой фазе все участники транзакции (шарды) подтверждают готовность выполнить операцию, а во второй — они либо подтверждают её выполнение, либо откатывают изменения.

Однако использование 2PC может значительно замедлить выполнение транзакций из-за необходимости ожидания подтверждений от всех шардов. Кроме того, в случае сбоя одного из участников система может попасть в состояние неопределённости, что потребует дополнительных механизмов для восстановления.

Другим подходом является использование eventual consistency, когда система соглашается на временное отсутствие полной согласованности, но гарантирует, что данные в конце концов станут согласованными. **Преимущества**:
- Обеспечивает согласованность и атомарность транзакций.
- Подходит для критичных операций, требующих высокой надёжности.

**Недостатки**:
- Высокие затраты на производительность и задержки.
- Потенциальные проблемы с восстановлением в случае сбоев.

[Схема 14: Двухфазный коммит]

## Основные проблемы шардирования и их решения

Шардирование решает проблему масштабирования, но вводит эксплуатационные вызовы, такие как горячие точки, сложность кросс-шардовых запросов и необходимость ребалансировки. Ниже приведены ключевые проблемы, их последствия и методы решения.

| **Проблема**                     | **Последствия**                                                                 | **Методы решения**                                                                 |
|----------------------------------|--------------------------------------------------------------------------------|------------------------------------------------------------------------------------|
| **Горячие точки (hot spots)**    | Перегрузка отдельных шардов, задержки, снижение производительности             | - Согласованное хэширование<br>- Динамическая ребалансировка<br>- Мониторинг нагрузки через Prometheus/Grafana |
| **Кросс-шардовые запросы**       | Увеличение задержек, сложность обеспечения согласованности                     | - Денормализация данных<br>- Federated Query Layer (Citus, Vitess)<br>- Кэширование результатов |
| **Добавление нового шарда**      | Потенциальный простой, необходимость перераспределения данных                  | - Online resharding с dual writes<br>- Middleware (Vitess, Citus)<br>- Постепенная миграция данных |
| **Несогласованность транзакций** | Ошибки в кросс-шардовых транзакциях, нарушение ACID                           | - Двухфазный коммит (2PC)<br>- Eventual consistency для некритичных операций<br>- Логирование транзакций |
| **Сложность маршрутизации**      | Неверная маршрутизация запросов, увеличение задержек                          | - Прокси-роутеры (ProxySQL, Vitess)<br>- Централизованный каталог (Consul, ZooKeeper)<br>- Согласованное хэширование |
| **Неравномерная нагрузка**       | Перегрузка части шардов, недозагрузка других                                  | - Автоматическая ребалансировка<br>- Асимметричное шардирование<br>- Мониторинг метрик (queries_per_shard) |

[Схема 15: Проблемы шардирования и их решения]

### Горячие точки

Горячие точки возникают, когда один шард получает непропорционально много запросов, например, при диапазонном шардировании, когда новые записи попадают в один диапазон.

**Решения**:
- Используйте согласованное хэширование для равномерного распределения.
- Мониторьте метрики нагрузки (`queries_per_shard` в Citus, `cpu_usage_per_shard` в Vitess) и настройте алерты через Prometheus.
- Перераспределяйте данные с помощью `rebalance_table_shards` (Citus) или `Reshard` (Vitess).

**Пример**: В социальной сети посты популярного блогера могут перегружать один шард. Решение — шардировать по хэшу `post_id` вместо `user_id`.

### Кросс-шардовые запросы
Запросы, затрагивающие несколько шардов, увеличивают задержки и сложность из-за необходимости координации.

**Решения**:
- **Денормализация**: Дублируйте данные для минимизации JOIN-ов. Например, храните имя пользователя в таблице заказов.
- **Federated Query Layer**: Используйте Citus или Vitess для оптимизации запросов.
- **Кэширование**: Кэшируйте результаты в Redis или Memcached.

### Добавление нового шарда
Решардирование может вызвать простои или ошибки, если данные переносятся неправильно.

**Решения**:
- **Online resharding**: Используйте dual writes для записи в старый и новый шард одновременно.
- **Middleware**: Citus и Vitess автоматизируют ребалансировку.
- **Ручное решардирование**: Подходит для небольших систем, но требует остановки записи.

### Несогласованность транзакций
Кросс-шардовые транзакции могут нарушать ACID из-за задержек или сбоев.

**Решения**:
- Используйте 2PC для атомарности.
- Применяйте eventual consistency для некритичных операций.
- Используйте affinity-шардирование для минимизации кросс-шардовых транзакций.

## Мониторинг и эксплуатация

Эффективная эксплуатация шардированной системы требует мониторинга ключевых метрик и настройки алертов.

- **Метрики**:
  - Размер шардов (`citus_shard_size` в Citus).
  - Количество запросов на шард (`queries_per_shard`).
  - Время выполнения кросс-шардовых запросов.
  - Прогресс ребалансировки (`resharding_progress` в Vitess).
- **Инструменты**:
  - **Prometheus + Grafana**: Визуализация метрик шардов.
  - **Vitess Dashboard**: Мониторинг состояния шардов и маршрутизации.
- **Практический вопрос**: Как настроить мониторинг горячих точек?
  - **Ответ**: Используйте Prometheus для сбора метрик `cpu_usage_per_shard` и настройте алерты на превышение порога. Анализируйте запросы через `EXPLAIN` и перераспределяйте данные при необходимости.

[Схема 16: Мониторинг шардированной системы]

## Компромиссы шардирования

Шардирование требует баланса между производительностью, сложностью и надёжностью:
- **Простота vs. масштабируемость**: Хэширование упрощает маршрутизацию, но усложняет аналитические запросы.
- **Производительность vs. согласованность**: Денормализация ускоряет запросы, но увеличивает объём данных и сложность синхронизации.
- **Автоматизация vs. контроль**: Middleware (Vitess, Citus) упрощает решардирование, но требует изучения и настройки.

Для социальной сети, где важна скорость, подойдёт хэширование и денормализация. Для финансовых систем, где критична согласованность, лучше использовать affinity-шардирование и 2PC.

[Схема 17: Сравнительная таблица компромиссов]

## Шардирование и репликация
Секционирование часто используется вместе с репликацией, благодаря чему каждая секция данных имеет несколько копий, размещённых на разных узлах. Это означает, что хотя конкретная запись принадлежит только одной секции, она может физически храниться на нескольких узлах для повышения отказоустойчивости. Один узел может содержать несколько секций. В случае репликации по модели «ведущий — ведомый» структура распределения будет следующей: для каждой секции выбирается ведущий узел, который принимает запись, а остальные — ведомые, синхронизирующиеся с ним. При этом один и тот же узел может одновременно быть ведущим для одних секций и ведомым для других.

[Схема 18: Шардирование с репликацией]

**Практический вопрос**: Как комбинировать шардирование и репликацию для высокой доступности?
- **Ответ**: Настройте репликацию для каждого шарда (например, один мастер и несколько слейвов). Используйте прокси (Vitess Proxy или ProxySQL) для маршрутизации чтения к слейвам и записи к мастерам. Мониторьте задержки репликации через метрики (`Seconds_Behind_Master` в MySQL) и настройте автоматический failover с помощью Consul или ZooKeeper.

## Вывод

Масштабирование реляционных баз данных — это важная задача для обеспечения их высокой производительности и доступности в условиях растущих объемов данных и запросов. Хотя реляционные БД традиционно славятся своей консистентностью и надежностью, с ростом требований к скорости обработки и масштабируемости, многие из них начинают сталкиваться с вызовами. Для решения этих проблем применяются различные подходы, такие как вертикальное и горизонтальное масштабирование, репликация и использование распределенных систем. Каждый из этих методов позволяет эффективно справляться с увеличивающейся нагрузкой, сохраняя при этом принципы работы реляционных БД. В будущем для достижения оптимальной производительности и гибкости, возможно, потребуется комбинированный подход, который объединяет традиционные реляционные технологии с новыми решениями, такими как NoSQL и распределенные системы, чтобы обеспечить быстрое и эффективное управление данными на всех уровнях. В процессе написания данной статьи собралось большое количество интересного материала который нам будет приятно осветить в дальнейших публикациях.
