# Масштабирование реляционных баз данных

![Масштабирование реляционных баз данных](https://github.com/user-attachments/assets/d0f03a9f-c79d-4121-aeb4-b221a74df53d)

## Введение

Информационные системы в современном мире сталкиваются с **необходимостью обработки растущих объемов данных**, что предъявляет высокие требования к производительности и отказоустойчивости баз данных. Реляционные СУБД, такие как PostgreSQL, MySQL и Microsoft SQL Server, остаются популярными благодаря своей надежности, строгой схеме данных и поддержке транзакций ACID. Однако при увеличении нагрузки традиционные подходы к проектированию реляционных баз данных могут стать узким местом, приводя к замедлению работы приложений и ухудшению пользовательского опыта.

Масштабирование реляционных баз данных — это комплекс методов, направленных на распределение нагрузки и обеспечение высокой доступности системы. Оно может быть **вертикальным** (увеличение ресурсов сервера) или **горизонтальным** (распределение данных между несколькими узлами). Каждый из этих подходов имеет свои преимущества и ограничения, а их выбор зависит от специфики приложения, бюджета и требований к отказоустойчивости.

В данной статье рассматриваются самые важные стратегии масштабирования реляционных баз данных, включая шардирование и репликацию. Также обсуждаются ключевые проблемы, такие как обеспечение согласованности данных, управление распределенными транзакциями и минимизация задержек в географически распределенных системах.

## Как можно масштабировать реляционные базы данных?

Реляционные базы данных (РБД) — основа многих приложений, но с ростом нагрузки их производительность может снижаться. Чтобы решить эту проблему, применяют два основных подхода: **вертикальное** (scale-up) и **горизонтальное** (scale-out) масштабирование.

### Вертикальное масштабирование

**Вертикальное масштабирование** (scale-up) остается самым простым и предсказуемым способом увеличения производительности реляционных СУБД. Этот подход подразумевает улучшение характеристик сервера: добавление процессорных ядер, увеличение оперативной памяти, использование более быстрых дисковых подсистем. Он не требует изменений в архитектуре приложения и сохраняет все преимущества реляционной модели.

#### Преимущества подхода
Главное достоинство вертикального масштабирования — его концептуальная простота. Администратору не нужно перестраивать логику работы приложения или беспокоиться о согласованности распределенных данных. Все транзакции продолжают выполняться на одном узле, гарантируя соблюдение принципов ACID. Это особенно важно для финансовых систем и приложений, где критична точность данных.

Технически масштабирование сводится к переносу БД на более мощный сервер или изменению конфигурации облачного инстанса. Например, переход с 4-ядерной виртуальной машины на 16-ядерную в AWS RDS может дать немедленный прирост производительности без необходимости изменять SQL-запросы или схему данных.

#### Ограничения и подводные камни
Однако у этого метода есть принципиальные ограничения. Физические пределы серверного оборудования создают естественный "потолок" для масштабирования. Современные серверы верхнего уровня могут иметь до нескольких терабайт RAM и сотни процессорных ядер, но их стоимость становится непропорционально высокой.

Экономика облачных решений усугубляет эту проблему. Цены на мощные инстансы растут нелинейно — переход с 8-ядерной конфигурации PostgreSQL на 64-ядерную может увеличить стоимость в 10-15 раз при реальном приросте производительности всего в 4-6 раз. Кроме того, остается проблема единой точки отказа — выход сервера из строя парализует всю систему.

#### Оптимальные сценарии применения
Вертикальное масштабирование хорошо подходит для систем с предсказуемым и умеренным ростом нагрузки. Например, корпоративные ERP-системы или специализированные отраслевые решения часто десятилетиями работают на вертикально масштабируемых конфигурациях.

Другой типичный случай — стартапы на этапе активного роста. Многие успешные компании (например, Dropbox на ранних этапах) сознательно откладывали переход на распределенные архитектуры, последовательно увеличивая мощность серверов. Это позволяло сосредоточиться на развитии продукта, а не на перестройке инфраструктуры.

#### Переходный этап
Важно понимать, что вертикальное масштабирование — это временное решение. Как показывает опыт Dropbox и других высоконагруженных систем, рано или поздно наступает момент, когда дальнейшее наращивание мощности сервера становится невозможным или экономически нецелесообразным. Однако грамотное использование этого метода позволяет отложить сложный переход к горизонтальному масштабированию до того момента, когда компания будет готова к таким изменениям технически и организационно.

### Горизонтальное масштабирование

**Горизонтальное масштабирование** предполагает добавление новых серверов или узлов в распределённую систему, что позволяет распределить нагрузку между несколькими экземплярами базы данных. Горизонтальное масштабирование может быть реализовано через **шардинг** и **репликацию**.

#### Репликация

**Репликация** — это процесс создания копий базы данных на разных серверах, которые могут использоваться для обработки запросов на чтение. Репликацию можно классифицировать по следующим характеристикам:
- **По архитектуре репликации** между собой выделяют: репликация с одним ведомым узлом (Master-slave replication), репликация с несколькими ведомыми узлами (Multi-master replication), репликация без ведомых узлов (Masterless replication).
- **По принципу синхронизации** на остальные узлы выделяют: асинхронную, синхронную и каскадную репликацию.
- **По уровню передачи данных** на остальные узлы выделяют: физическую и логическую репликацию.

..тут можно ещё что-то добавить, чтобы текст читался более лаконично...

##### Master-Slave репликация

###### Основные положения

Один из наиболее распространённых подходов — **Master-Slave репликация** (также известная как Primary-Replica).

[Схема 1: схема работы Master-slave репликации]

Эта модель предполагает строгое разделение ролей между узлами: один сервер (master) принимает все операции записи и какую-то часть операций на чтение, а один или несколько подчинённых серверов (slave) синхронизируют данные и обслуживают запросы только на чтение.

Давайте представим, как на самом деле работает эта система. Когда вы отправляете запрос на изменение данных - будь то добавление новой записи (INSERT), обновление существующей (UPDATE) или удаление (DELETE) - всё начинается с **мастер-узла**. Это главный распорядитель, который первым принимает все изменения. Но самое интересное начинается потом, когда эти изменения нужно разослать подчинённым узлам.

###### Уровень передачи данных между узлами

Здесь система предлагает два принципиально разных подхода, каждый со своей особенностью. Первый - это **физическая репликация**, где данные передаются в своём "сыром", нетронутом виде, как есть

[Схема 1: формат данных, который передаётся из узела в узел]

Представьте, что мастер просто фотографирует свои бинарные логи - те самые WAL в PostgreSQL или binlog в MySQL - и рассылает эти снимки слейвам. Красота этого метода в его простоте и точности: реплики получают данные в точно таком же виде, в каком они существуют на мастере. Но за эту точность приходится платить - все узлы должны быть похожи как близнецы, работать на совместимом железе и одинаковых версиях ПО.

...можно привети примеры, как это сделано в PostgreSQL и MySQL...

А теперь второй подход - **логическая репликация** - это уже более интеллектуальный способ общения между узлами

[Схема 2: формат данных, который передаётся из узела в узел]

Здесь мастер не просто копирует данные, а фактически пересказывает, что именно произошло: "Я только что добавил новую запись в таблицу пользователей", или "Я обновил цену в товаре с ID 42". Это как разница между отправкой фотографии документа и его кратким изложением по телефону. Такой подход куда более гибкий - он позволяет реплицировать только отдельные таблицы, работать с разными версиями СУБД и даже немного корректировать данные по пути.

...можно привети примеры, как это сделано в PostgreSQL и MySQL...

И в этом танце данных есть ещё один важный ритм - **принцип синхронизации**, который будет рассмотрен в следующей главе.

###### Принципу синхронизации данных между узлами

В системах репликации данных применяются два принципиально разных подхода, различающихся по своим гарантиям и характеристикам производительности. Рассмотрим их ключевые особенности.

**Синхронная репликация** обеспечивает максимальную надежность за счет строгого порядка операций. При получении запроса на запись мастер-узел сначала рассылает данные всем репликам и ожидает явного подтверждения от каждой из них. Только после получения подтверждений от всех реплик (или заданного кворума) операция считается успешной и клиент получает ответ. Такой подход гарантирует сохранность данных и их согласованность на всех узлах, но имеет существенные ограничения. Производительность системы определяется самым медленным узлом, а географическая распределенность значительно увеличивает задержки. Главный недостаток - отказ даже одной реплики приводит к невозможности подтверждения операций, что может парализовать всю систему.

[Схема 4: последовательность при синхронной репликации]

**Асинхронная репликация** предлагает противоположный компромисс. Мастер-узел подтверждает запись клиенту сразу после локального выполнения, не дожидаясь обработки репликами. Изменения передаются подчиненным узлам в фоновом режиме по мере возможности. Это обеспечивает высокую производительность и устойчивость к временным сбоям реплик, поскольку система продолжает работать даже при их недоступности. Однако такой подход несет риски потери данных - если мастер выйдет из строя до завершения синхронизации, последние изменения могут быть утрачены. Кроме того, реплики могут временно содержать неактуальные данные.

[Схема 3: последовательность действий при асинхронной репликации]

Основное различие между подходами заключается в ключевом компромиссе распределенных систем - между надежностью и производительностью. Синхронная репликация обеспечивает максимальную сохранность данных, но ценой снижения скорости работы и доступности системы. Асинхронная репликация, напротив, предлагает высокую производительность и отказоустойчивость, однако допускает возможность потери данных и временной несогласованности - эти аспекты мы подробно рассмотрим далее.

| Проблема |	Последствия	| Методы решения |
|----------|--------------|----------------|
| Временная рассогласованность | Пользователи видят устаревшие данные |	- Временные маркеры "обновляется" - Чтение после записи (read-after-write) для критичных данных
| Риск потери данных | Последние изменения пропадают при сбое мастера |	- Полусинхронная репликация для критичных операций - WAL-логи с подтвержденной записью
| Конфликты обновлений | Конкурирующие изменения на разных узлах | - Векторные часы для определения порядка - Алгоритмы разрешения конфликтов (CRDT)
| Накопление отставания |	Реплики не успевают за мастером при нагрузке | - Автомасштабирование реплик - Ограничение скорости записи

**Потеря данных при сбое основной ноды**

Асинхронная репликация подразумевает, что данные сначала записываются на мастер ноду, а затем (с задержкой, другими словами создаётся окно неконсистентности данных) отправляются на реплики. Если основная нода выходит из строя до того, как изменения попали на реплики, такие данные теряются.

**Полу-синхронная репликация** (Semi-synchronous replication) - включает промежуточный этап, при котором транзакция считается завершённой только после того, как хотя бы одна реплика подтвердила получение данных. Это снижает вероятность потери данных сохраняя приемлемую производительность.

**Журналирование на клиентской стороне** - клиенты могут логировать транзакции до подтверждения их основным узлом и повторно отправлять при сбое. Однако этот подход усложняет архитектуру.

**Введение промежуточного кэширующего слоя (например, WAL Proxy)** - Данные сначала пишутся в устойчивый лог, который одновременно ретранслируется в мастера и реплики.

**Задержка репликации (replication lag)**

Из-за отсутствия синхронизации в реальном времени, данные на репликах могут отставать от мастера на значительное время, особенно под высокой нагрузкой.

**Мониторинг и алерты по lag-метрикам** - использование метрик вроде Seconds_Behind_Master (MySQL) позволяет отслеживать задержку. В случае повышения порогов можно временно исключить реплику из пула чтения.

**Разделение нагрузки между мастером и репликами** - Минимизация чтений/записей, чтобы уменьшить отставание.

**Использование более эффективных протоколов репликации** - например, физическая репликация быстрее логической, особенно при большом количестве DML-операций.

**Аппаратные улучшения** - быстрые диски (NVMe), оптимизация сетевого стека, увеличесние буферов и размер пакетов в настройках репликации.

**Несогласованность данных**

Из-за задержки данные на репликах не гарантируют точного соответствия мастеру. Это особенно критично для сценариев, где читается недавно записанная информация (Read-Your-Writes Consistency).

**Согласованное маршрутизирование запросов** - использование middleware или proxy, которые маршрутизируют клиентские запросы так, чтобы клиенты после записи всегда читали с мастера.

**Версионирование данных** - система может отслеживать версии объектов и сравнивать их между узлами, обеспечивая согласованность при необходимости.

**Использование CRDT** (???) - для специфических доменов можно применять структуры, допускающие асинхронную репликацию с разрешением конфликтов без потери данных.

**Failover и Split-Brain**

В случае выхода мастера из строя и автоматического переключения на реплику може произойти ситуация split-brain - одновременная запись в два несовместимых источника истины.

**Использование механизмов quorum'a** - репликация и выбор мастера осуществляется на основе большинства (например, через Raft или Paxos), исключая возможность split-brain

**Fencing токены (например, Zookeeper fencing)** - каждому лидеру выдаётся уникальный токен, предотвращающий "двойное лидерство"

**Использование consensus-сервисов** - etcd, consul, zookeeper обеспечивает отказоустойчивый контроль за лидерством и конфигурацией.

**Выбор стратегий автоматического или ручного failover** - в критичных системах предпочтительнее использовать ручной failover с предварительным анализом состояния реплик.

На практике часто используют **гибридные решения**. Например, в PostgreSQL можно настроить синхронную репликацию только для критически важных транзакций, а всё остальное пускать асинхронно.

[Схема 5: пример гибридной настройки]

Или сделать синхронной только одну из нескольких реплик — это даёт баланс между надёжностью и производительностью.

Главный выбор здесь — между скоростью и надёжностью. Для социальной сети, где можно на секунду потерять последний лайк, подойдёт асинхронный вариант. А для банковских операций или медицинских систем, где каждая запись должна быть сохранена наверняка, без синхронной репликации не обойтись

[Схема 6: сравнительная таблица подходов]

##### Multi-Master репликация

Представьте базу данных, где не один, а сразу несколько серверов могут принимать запросы на запись. Это не классическая master-slave схема, к которой многие привыкли, а более современный и гибкий подход — multi-master репликация. Но в чём принципиальная разница между этими подходами и когда стоит выбирать каждый из них? Почему это вообще понадобилось?

Классическая master-slave схема долгое время была стандартом де-факто. Один главный сервер принимает все записи, а его подчинённые лишь читают данные. Просто, надёжно, но... Когда приложение растёт, этот единственный мастер превращается в узкое горлышко. Представьте стадион с сотней входов, но только одной кассой — очереди неизбежны.

Именно здесь multi-master репликация предлагает элегантное решение. Теперь касс несколько, и посетители могут выбирать любую. Для глобальных сервисов это особенно ценно — пользователи в разных частях света пишут в ближайший к ним узел, не испытывая задержек из-за расстояний.

Как это работает в реальности?

Допустим, у нас два мастера — в Москве и во Владивостоке. Пользователь из Приморья вносит изменения, которые сначала попадают на локальный узел. Фокус в том, что система не заставляет его ждать, пока данные доберутся до московского сервера. Вместо этого она говорит: "Хорошо, я приняла твои изменения здесь, а синхронизацией займусь потом".

Это "потом" — ключевой момент. Репликация происходит асинхронно, что даёт потрясающую отзывчивость, но создаёт интересные ситуации. Например, пока изменение путешествует между узлами, два пользователя в разных городах могут видеть разное состояние одних и тех же данных. Но всё не так просто, как кажется.

Главная головоломка multi-master — конфликты. Что если два мастера одновременно изменят одну и ту же запись? Здесь в игру вступают различные стратегии:
- Можно просто взять последнее изменение по времени (Last Write Wins)
- Или попытаться объединить изменения (как это делает Git при мердже веток)
- А иногда приходится звать администратора, чтобы он вручную разобрался, чья правда важнее

Ещё один нюанс — производительность. Казалось бы, больше серверов — больше мощности. Но вся эта синхронизация между узлами съедает немало ресурсов. Порой проще нарастить один мощный сервер, чем городить кластер.

Когда это действительно нужно?
- Если ваше приложение:
- Распределено географически
- Испытывает высокую нагрузку на запись
- Может мириться с временными несоответствиями данных

...то multi-master может стать отличным выбором. Но для банковских систем или там, где важна абсолютная согласованность, лучше поискать другие варианты.

##### Каскадная репликация

Это тип репликации, при котором слейв-сервер может быть реплицирован на другие слейв-сервера. В этой архитектуре изменения, сделанные на **мастер-сервере**, сначала транслируются на первый уровень реплик, а затем от них — к последующим репликам.

Преимущества каскадной репликации:
- **Оптимизация нагрузки**: Избегается перегрузка мастера и первого уровня реплик, так как реплики могут делегировать часть своих запросов другим репликам.
- **Масштабируемость**: Легко расширять систему за счёт добавления новых слейв-реплик на каждом уровне, что позволяет эффективно распределять нагрузку.
- **Уменьшение трафика на мастер-сервере**: Мастер-сервер загружен только первичной репликацией, а остальные реплики могут передавать данные каскадно, снижая нагрузку на основную базу данных.

Недостатки каскадной репликации:
- **Дополнительная задержка**: Из-за того, что данные передаются через несколько уровней реплик, возникает дополнительная задержка в репликации данных, что может привести к рассогласованию на разных уровнях.
- **Сложность в настройке и управлении**: Поддержка каскадной репликации требует более сложной настройки и мониторинга, так как нужно отслеживать состояние всех уровней реплик.

#### Шардинг (Sharding)

**Шардинг** — это техника логического разделения данных на независимые сегменты, называемые шардами, каждый из которых может храниться и обрабатываться отдельным сервером. Благодаря этому можно значительно повысить пропускную способность системы и устранить узкие места в производительности. Важно, что каждый элемент данных принадлежит только одному шару, что упрощает маршрутизацию запросов и минимизирует избыточность.

Существует два основных типа шардирования:
- **Горизонтальный** - разделение данных по строкам: каждая таблица дублируется на всех узлах, но содержит разные записи.
- **Вертикальный** - разделение по столбцам: каждый узел хранит только определённые поля таблиц или подмножества таблиц, соответствующие различным подсистемам.

Методов определения, к какому шарду должны попасть данные, существует множество, каждый из которых подходит под разные сценарии использования:
- Хеширование ключа (hash-based) — применяется хеш-функция к уникальному ключу записи. Полученное значение определяет шард, в который отправятся данные. Этот подход обеспечивает равномерное распределение, но затрудняет выполнение диапазонных запросов.
- Диапазон значений (range-based) — данные распределяются по диапазонам значений, например: ID 1–1000 в один шард, 1001–2000 в другой. Удобен для аналитических и выборочных операций, но подвержен риску "горячих точек" при неравномерном росте данных.
- Географическое шардирование (geo-based) — данные делятся по региональному признаку, чтобы минимизировать сетевые задержки. Часто используется в глобальных системах для локализации трафика.
- Функциональное (или доменное) шардирование — распределение по логике приложения: одни таблицы (например, пользователи) идут в один кластер, другие (например, заказы или логи) — в другой. Часто применяется в микросервисных архитектурах.
- Динамический или автоматический шардинг — распределение и перераспределение данных осуществляется автоматически в зависимости от текущей нагрузки, объёма или плотности данных. Такие механизмы используются, например, в MongoDB, CockroachDB или Vitess.


  ### Добавление нового шарда
  С увеличением объёма данных и ростом нагрузки на систему может возникнуть необходимость в добавлении новых шардов для поддержания масштабируемости. Это достаточно сложный процесс, который требует точной координации и внимательного подхода, чтобы минимизировать влияние на производительность и доступность системы.
Основные подходы добавления нового шарда

Процесс добавления нового шарда зависит от используемой архитектуры и инструментов, однако существует несколько общих стратегий, которые могут быть применены в разных случаях.
1. Ручное решардирование

Решардирование вручную — это базовый подход, при котором данные переносятся с существующих шардов на новый вручную, а затем обновляется конфигурация маршрутизации запросов. Это довольно трудоёмкий процесс, требующий точности, поскольку ошибки могут привести к несогласованности данных или к нарушению работы системы.

Решардирование вручную обычно включает несколько этапов:

   - Создание нового шарда с соответствующей конфигурацией.

   - Перераспределение данных, например, с помощью скриптов или специализированных утилит.

   - Обновление маршрутизации запросов, чтобы новые данные могли быть направлены на свежий шард.

   - Обеспечение целостности данных в процессе переноса.

Этот метод подходит для систем, где перерывы в обслуживании или небольшие простои могут быть допустимы, или для простых систем с относительно небольшим количеством шардов.
Преимущества:

   - Полный контроль над процессом.

   - Гибкость в решении уникальных задач.

📍Место для иллюстрации: схема с показом процесса вручную перераспределения данных между шардов.
2. Решардирование с использованием Middleware

Множество современных распределённых СУБД применяют middleware решения, такие как Vitess, Citus или Yugabyte, которые автоматизируют процесс ребалансировки данных и обновления маршрутов запросов без необходимости в даунтайме. Эти инструменты абстрагируют сложность решардирования и обеспечивают непрерывную работу системы в процессе расширения.

Vitess (к примеру) управляет шардами и отвечает за автоматическое перераспределение данных, когда добавляются новые шарды. Это позволяет избежать простоя системы и минимизировать риски, связанные с человеческим фактором.
Преимущества:

   - Автоматизация процесса решардирования.

   - Минимизация простоя и рисков ошибок.

   - Высокая степень интеграции с современными распределёнными СУБД.

📍Место для иллюстрации: схема с изображением распределённой СУБД, где middleware управляет перераспределением данных между несколькими шардовыми узлами.
3. Прокси или маршрутизаторы

Прокси-сервера или маршрутизаторы — это подход, при котором добавление новых шардов происходит без изменений на стороне клиента. В этом случае на промежуточном уровне (например, с использованием инструмента типа ProxySQL или Vitess Proxy) работает маршрутизатор, который управляет распределением запросов и определяет, какой шард обслуживает каждый запрос.

Когда добавляется новый шард, маршрутизатор автоматически перенаправляет запросы на правильные узлы, что позволяет масштабировать систему без необходимости изменять клиентскую логику.
Преимущества:

   - Отсутствие изменений в логике приложения.

   - Простота интеграции новых шардов.

   - Снижение операционных рисков, связанных с изменениями на клиентской стороне.

📍Место для иллюстрации: схема, где прокси-серверы управляют запросами и направляют их на нужные шарды, без изменений в клиентской логике.
4. Online Resharding и Dual Writes

Чтобы минимизировать даунтайм и риски потери данных, при добавлении нового шарда часто используется online resharding. Этот метод включает в себя использование dual writes — временной записи данных как в старые, так и в новые шарды. Во время такого процесса данные пишутся одновременно в оба шарда (старый и новый), а затем проводится фоновый перенос данных на новый шард.

Процесс может включать следующие этапы:

   - Включение временной записи в оба шардовых узла (старый и новый).

   - Постепенный перенос данных на новый шард в фоновом режиме.

   - По завершению переноса данных — остановка записи на старый шард.

Этот метод помогает свести к минимуму время простоя и гарантировать, что все записи данных будут успешными, даже если они происходят во время переноса.
Преимущества:

   - Минимизация времени простоя.

   - Обеспечение целостности данных в процессе переноса.

📍Место для иллюстрации: схема с изображением процесса online resharding, где данные временно пишутся в два шарда.

### Балансировка нагрузки
Шардирование должно обеспечивать равномерную нагрузку на все узлы. Без должной балансировки даже при наличии множества шардов часть из них может перегружаться, в то время как другие остаются незадействованными.
- При range-шардировании часто возникают горячие шарды, особенно если новые записи всегда попадают в один и тот же диапазон.
- Hash-шардирование даёт более равномерное распределение, но при добавлении новых шардов необходимо перераспределение ключей.
(дописать jump hashing)

Перед тем как более подробно рассмотрим каждый из методов, необходимо предварительно рассмотреть несколько важных терминов

Горячая точка - Узел, шард или участок данных, на который приходится слишком много запросов, в результате чего возникает перегрузка и снижение производительности.

Согласованное хэширование - метод распределения данных по узлам так, что при добавлении/удалении узлов изменяется минимум ключей. Использует кольцо хэшей и назначает данные ближайшему узлу по часовой 
стрелке.

Ассиметричный шардинг- разделение данных между узлами неравномерно, по размеру, нагрузке или логике. Один шард может быть больше или обслуживать больше запросов, чем другие.

Терм - токен (ключ, значение или атрибут), по которому строится вторичный индекс.

### Affinity Anti-Affinity
По мере роста объёма данных и распределения нагрузки по нескольким шардовым узлам перед разработчиками встаёт не только задача эффективного масштабирования, но и вопрос логического размещения данных. Одним из ключевых принципов, влияющих на производительность и устойчивость системы, становится выбор между affinity и anti-affinity стратегиями при шардинге.
Affinity: стремление к связности

Affinity (от англ. "связанность") — это архитектурный принцип, согласно которому логически связанные сущности (например, пользователь и его заказы) хранятся в одном и том же шарде. Такой подход облегчает выполнение транзакций, ускоряет JOIN-запросы и снижает частоту кросс-шардового взаимодействия.

Представим себе систему электронной коммерции: пользователь, его корзина, заказы и платежи — все эти данные постоянно взаимодействуют друг с другом. Если они размещены на одном узле, система может обрабатывать типичные запросы (например, «показать историю заказов пользователя») без необходимости обращаться к другим шардовым нодам. Это особенно критично для OLTP-нагрузок, где важны транзакционность и задержки.
Преимущества affinity-шардинга

   - Минимизация сетевого взаимодействия. Все данные находятся рядом — запросы не пересекают границы шардов.

   - Ускорение транзакций. В большинстве СУБД транзакции внутри одного узла значительно быстрее и проще, чем мультишардовые.

   - Простота обеспечения согласованности. Принципы ACID легко соблюдаются, поскольку нет необходимости координировать изменения между несколькими шардами.

📍Место для иллюстрации: схема, где пользователь и все связанные с ним данные (Orders, Payments, Cart) хранятся в одном шарде. Стрелки между ними не покидают границы узла.
Anti-Affinity: диверсификация и устойчивость

В противоположность подходу "всё в одном месте", anti-affinity предполагает преднамеренное разнесение логически связанных сущностей по разным шардам. На первый взгляд это усложняет архитектуру, но на практике часто оказывается необходимым для повышения отказоустойчивости и распределения нагрузки.

Такой подход полезен, например, в системах, где одна группа данных может полностью "захватить" узел. Допустим, крупный клиент в CRM-системе начинает активно генерировать активность (например, тысячами создаёт записи). Если все его данные хранятся на одном узле — это быстро приводит к перегрузке. Разнесение данных клиента по нескольким шардам помогает сбалансировать нагрузку.
Преимущества anti-affinity-шардинга

   - Изоляция сбоев. Сбой одного шарда не приводит к полной недоступности данных определённого пользователя или сегмента.

   - Лучшее распределение нагрузки. Даже активные клиенты не перегружают один узел.

   - Масштабируемость по ширине. Легче равномерно расти за счёт увеличения числа нод.

📍Место для иллюстрации: та же структура, что в предыдущем примере, но теперь каждый компонент пользователя (Orders, Payments, Cart) находится на разных шардах. Стрелки пересекают границы.
Когда применять каждый подход

Выбор между affinity и anti-affinity нельзя считать универсальным — он зависит от требований системы:
Сценарий	Предпочтительный подход
Высокочастотные JOIN-запросы	Affinity
Низкий уровень доверия к одному узлу	Anti-affinity
Работа с транзакциями	Affinity
Доминирование одного клиента в нагрузке	Anti-affinity
Высокие требования к отказоустойчивости	Anti-affinity
Минимизация сетевых задержек	Affinity

Некоторые современные системы (например, Spanner, CockroachDB, YugabyteDB) реализуют динамические стратегии размещения данных, где принципы affinity применяются гибко: в зависимости от текущей активности узел может "перетягивать" к себе связанные данные, чтобы уменьшить межшардовое взаимодействие.
Гибридный подход

На практике чаще всего используется гибридный подход: наиболее важные логические связи группируются внутри шарда, а второстепенные — распределяются по другим узлам. Например, можно гарантировать, что пользователь и его заказы всегда на одном шарде, но его активность в чатах или история входов может храниться отдельно.

Такой компромисс позволяет соблюсти баланс между производительностью, отказоустойчивостью и масштабируемостью.

#### Маршрутизация
Мы распределили данные по нескольким узлам на разных машинах, но остаётся важный вопрос: как клиенту определить, к какому узлу обратиться при выполнении запроса?
Когда секции (шарды) перераспределяются — например, при добавлении или удалении узлов — меняется и их размещение. Поэтому нужен централизованный механизм, который будет отслеживать текущее состояние кластера и сможет сообщить клиенту куда обратиться чтобы получить нужные данные.
В общем случае это называется Service Discovery, если эта тема интересна, разберем ее в следующей статье.А в частности — существует множество подходов к реализации service discovery в системах с шардированием и динамическим масштабированием. Вот несколько популярных решений и стратегий:
- Централизованный каталог (реестр) узлов: Системы вроде Consul, etcd или ZooKeeper хранят актуальную информацию о том, какие шарды где находятся.
Клиенты или прокси могут запрашивать у них адрес нужного узла, отвечающего за конкретный диапазон данных.
- Прокси-роутер перед клиентами: Клиенты обращаются не напрямую к узлам, а к прокси-серверу, который уже знает всё о текущем состоянии шардинга и маршрутизирует запросы.
Такой подход используется, например, в Vitess (MySQL) или Citus (PostgreSQL).
- Согласованное хэширование (Consistent Hashing): Клиент сам вычисляет, к какому узлу ему нужно обратиться, используя кольцо хэшей. Но при этом должен знать текущее состояние узлов (карту кольца), которая всё равно должна где-то поддерживаться — например, через тот же etcd.
-  DNS-based Discovery (через обновляемые DNS-записи): адреса сервисов или узлов обновляются через DNS. Преимущество — простота, но минус в том, что обновления не мгновенные и не дают детального контроля.
-  Kubernetes API для сервисов в k8s: В Kubernetes discovery встроен: клиенты узнают адреса подов и сервисов через Kube DNS или API Kubernetes. Также поддерживаются headless-сервисы для доступа напрямую к подам.
   ### Косс-шардовые запросы

При работе с распределёнными базами данных часто возникает необходимость выполнения запросов, которые требуют данных из нескольких шардов. Это приводит к нескольким техническим проблемам и увеличивает сложность обработки таких запросов. Рассмотрим основные методы решения этих проблем и подходы к оптимизации кросс-шардовых запросов.
1. Fan-out

Fan-out — это подход, при котором запрос рассылается на все шардовые узлы, и результаты агрегируются в едином месте. Такой метод полезен, когда необходимо выполнить однотипную операцию на всех шардах, например, когда нужно собрать информацию о пользователях с разных регионов или выполнить поиск по всем данным.

Проблемы:

   - Производительность: чем больше шардов, тем дольше будет время отклика, так как запросы должны быть отправлены на каждый шард и потом собраны.

   - Согласованность: могут возникнуть проблемы с синхронизацией данных между шардовыми узлами, особенно если на одном из шардов произошли изменения во время выполнения запроса.

Для оптимизации этого подхода часто используется кеширование промежуточных результатов, чтобы избежать повторной обработки одинаковых запросов.
Преимущества:

   - Простота реализации.

   - Подходит для аналитических запросов, где важно собрать данные с нескольких источников.

📍Место для иллюстрации: схема с отображением запросов, которые рассылались на все шардовые узлы, с последующей агрегацией результатов.
2. Federated Query Layer

Federated Query Layer — это промежуточный слой, который анализирует запрос, разбивает его на подзапросы и затем собирает итоговый результат. Этот подход позволяет выполнять кросс-шардовые запросы более эффективно, так как промежуточный слой может оптимизировать запросы, направлять их только на те шарды, которые содержат нужные данные, а затем агрегировать результаты.

Примером таких решений являются Citus или Vitess, которые могут анализировать запросы и автоматически распределять их между нужными шардовыми узлами, минимизируя нагрузку.
Преимущества:

   - Эффективное распределение запросов.

   - Уменьшение нагрузки на каждый отдельный шард.

   - Возможность реализации сложных аналитических запросов через единый интерфейс.

📍Место для иллюстрации: схема с промежуточным слоем, который анализирует запросы и направляет их на соответствующие шарды.
3. Денормализация

Денормализация — это метод, при котором данные из разных таблиц или шардов могут дублироваться для минимизации необходимости в кросс-шардовых JOIN-ах. Этот подход помогает ускорить запросы, так как вместо того, чтобы делать JOIN между шардовыми узлами, все необходимые данные уже присутствуют в одном месте.

Такой подход используется в распределённых системах, где производительность важнее, чем точная нормализация данных. Например, можно создать отдельные таблицы с денормализованными данными, которые будут содержать всю информацию, необходимую для определённых типов запросов.
Преимущества:

   - Ускоряет выполнение запросов, уменьшив количество кросс-шардовых операций.

   - Снижается нагрузка на сеть и увеличивается скорость обработки данных.

Недостатки:

   - Увеличение объёма данных.

   - Требуется дополнительная логика для синхронизации дублированных данных при изменениях.

📍Место для иллюстрации: схема с денормализованной таблицей, содержащей данные, которые обычно распределены по нескольким шардам.
4. Кросс-шардовые транзакции

Кросс-шардовые транзакции — это сложные транзакции, которые охватывают несколько шардов. Реализация таких транзакций требует особого подхода для обеспечения целостности и согласованности данных. Наиболее распространённым решением является использование двухфазного коммита (2PC).

   2PC (Two-Phase Commit) — это протокол, который обеспечивает атомарность транзакций. Он состоит из двух фаз: в первой фазе все участники транзакции (шарды) подтверждают готовность выполнить операцию, а во второй — они либо подтверждают её выполнение, либо откатывают изменения.

Однако использование 2PC может значительно замедлить выполнение транзакций из-за необходимости ожидания подтверждений от всех шардов. Кроме того, в случае сбоя одного из участников система может попасть в состояние неопределённости, что потребует дополнительных механизмов для восстановления.

Другим подходом является использование eventual consistency, когда система соглашается на временное отсутствие полной согласованности, но гарантирует, что данные в конце концов станут一致ными.
Преимущества:

   - Обеспечивает согласованность и атомарность транзакций.

   - Подходит для критичных операций, требующих высокой надёжности.

Недостатки:

   - Высокие затраты на производительность и задержки.

   - Потенциальные проблемы с восстановлением в случае сбоев.

📍Место для иллюстрации: схема двухфазного коммита с показом этапов транзакции на разных шардах.

#### Шардирование и репликация
Секционирование часто используется вместе с репликацией, благодаря чему каждая секция данных имеет несколько копий, размещённых на разных узлах. Это означает, что хотя конкретная запись принадлежит только одной секции, она может физически храниться на нескольких узлах для повышения отказоустойчивости.
Один узел может содержать несколько секций. В случае репликации по модели «ведущий — ведомый» структура распределения будет следующей: для каждой секции выбирается ведущий узел, который принимает запись, а остальные — ведомые, синхронизирующиеся с ним.
При этом один и тот же узел может одновременно быть ведущим для одних секций и ведомым для других.

## Вывод

Масштабирование реляционных баз данных — это важная задача для обеспечения их высокой производительности и доступности в условиях растущих объемов данных и запросов. Хотя реляционные БД традиционно славятся своей консистентностью и надежностью, с ростом требований к скорости обработки и масштабируемости, многие из них начинают сталкиваться с вызовами. Для решения этих проблем применяются различные подходы, такие как вертикальное и горизонтальное масштабирование, репликация и использование распределенных систем. Каждый из этих методов позволяет эффективно справляться с увеличивающейся нагрузкой, сохраняя при этом принципы работы реляционных БД. В будущем для достижения оптимальной производительности и гибкости, возможно, потребуется комбинированный подход, который объединяет традиционные реляционные технологии с новыми решениями, такими как NoSQL и распределенные системы, чтобы обеспечить быстрое и эффективное управление данными на всех уровнях.
